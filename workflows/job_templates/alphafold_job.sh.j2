#!/bin/bash
#SBATCH --job-name=af3_{{ protein_name }}
#SBATCH --output={{ logs_dir }}/%x_%j.out
#SBATCH --error={{ logs_dir }}/%x_%j.err
#SBATCH --partition={{ partition }}
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task={{ cpus }}
#SBATCH --gres=gpu:h200:1
#SBATCH --mem={{ memory }}
#SBATCH --time=02:00:00
{% if email %}
#SBATCH --mail-user={{ email }}
#SBATCH --mail-type=ALL
{% endif %}

# Load modules
module load miniconda3/24.11.1
module load schrodinger/2024-4

# Set up environment
source $(conda info --base)/etc/profile.d/conda.sh
conda activate fade

# Set AlphaFold3 paths - required for container execution
export DATA_PATH=/shared/container_repository/AlphaFold/database
export MODEL_PATH=/projects/SimBioSys/share/software/AF3/models

# Load configuration
CONFIG_FILE="{{ config_file }}"
PROTEIN_NAME="{{ protein_name }}"

echo "Starting AlphaFold3 prediction for ${PROTEIN_NAME}"
echo "Using configuration file: ${CONFIG_FILE}"
echo "DATA_PATH: ${DATA_PATH}"
echo "MODEL_PATH: ${MODEL_PATH}"

# Parse configuration
SEQUENCE_FILE=$(cat ${CONFIG_FILE} | jq -r '.sequence_file')
OUTPUT_DIR=$(cat ${CONFIG_FILE} | jq -r '.output_dir')
MAX_TEMPLATE_DATE=$(cat ${CONFIG_FILE} | jq -r '.max_template_date')
MODEL_PRESET=$(cat ${CONFIG_FILE} | jq -r '.model_preset')
DB_PRESET=$(cat ${CONFIG_FILE} | jq -r '.db_preset')
NUM_RECYCLE=$(cat ${CONFIG_FILE} | jq -r '.num_recycle')
ENABLE_AMBER_RELAX=$(cat ${CONFIG_FILE} | jq -r '.enable_amber_relax')

# Create output directory
mkdir -p ${OUTPUT_DIR}

# Create AlphaFold3 input JSON file
AF3_INPUT_JSON="${OUTPUT_DIR}/${PROTEIN_NAME}_af3_input.json"

# Read FASTA file content
FASTA_CONTENT=$(cat ${SEQUENCE_FILE})
SEQUENCE=$(echo "${FASTA_CONTENT}" | grep -v "^>" | tr -d '\n')
SEQUENCE_ID=$(echo "${FASTA_CONTENT}" | grep "^>" | sed 's/^>//' | head -n 1)

# Create the AlphaFold3 input JSON format
cat > ${AF3_INPUT_JSON} << EOF
{
  "name": "${PROTEIN_NAME}",
  "sequences": [
    {
      "protein": {
        "id": "${SEQUENCE_ID}",
        "sequence": "${SEQUENCE}"
      }
    }
  ],
  "dialectSettings": {
    "max_template_date": "${MAX_TEMPLATE_DATE}",
    "model_preset": "${MODEL_PRESET}",
    "db_preset": "${DB_PRESET}",
    "num_recycle": ${NUM_RECYCLE}
  }
}
EOF

echo "Created AlphaFold3 input JSON: ${AF3_INPUT_JSON}"
cat ${AF3_INPUT_JSON}

# Run AlphaFold3 using Singularity container with the new format
echo "Running AlphaFold3..."

singularity exec --nv \
    --bind ${DATA_PATH}:/data \
    --bind ${MODEL_PATH}:/models \
    --bind ${OUTPUT_DIR}:/output \
    /shared/container_repository/AlphaFold/alphafold3.sif \
    python /app/alphafold/run_alphafold.py \
    --json_path=/output/$(basename ${AF3_INPUT_JSON}) \
    --output_dir=/output \
    --db_dir=/data \
    --model_dir=/models

echo "AlphaFold3 prediction completed"

# Extract best model (updated for new output format)
BEST_MODEL=$(find ${OUTPUT_DIR} -name "*rank_001*.pdb" | head -n 1)
if [ -z "${BEST_MODEL}" ]; then
    # Try alternative naming patterns
    BEST_MODEL=$(find ${OUTPUT_DIR} -name "*model_0*.pdb" | head -n 1)
fi

if [ ! -z "${BEST_MODEL}" ]; then
    BEST_MODEL_BASENAME=$(basename ${BEST_MODEL})
    cp ${BEST_MODEL} ${OUTPUT_DIR}/${PROTEIN_NAME}_best_model.pdb
    echo "Best model saved as: ${OUTPUT_DIR}/${PROTEIN_NAME}_best_model.pdb"
else
    echo "No best model found. Checking available files:"
    ls -la ${OUTPUT_DIR}/
fi

echo "Job completed for ${PROTEIN_NAME}"